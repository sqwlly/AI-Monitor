#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Claude Monitor Context Fusion
ä¸Šä¸‹æ–‡èåˆå™¨ - æ•´åˆå¤šæºä¿¡æ¯ç”Ÿæˆä¼˜åŒ–çš„ LLM ä¸Šä¸‹æ–‡

åŠŸèƒ½ï¼š
1. å¤šæºä¿¡æ¯èåˆï¼ˆç»ˆç«¯è¾“å‡º/æ–‡ä»¶å˜æ›´/GitçŠ¶æ€/é¡¹ç›®ç»“æ„/å†å²å†³ç­–ï¼‰
2. ä¿¡æ¯ä¼˜å…ˆçº§æ’åº
3. ä¸Šä¸‹æ–‡å‹ç¼©ï¼ˆå»é‡/æ‘˜è¦/å…³é”®ä¿¡æ¯æå–ï¼‰
4. ä¸Šä¸‹æ–‡æ ¼å¼åŒ–ï¼ˆä¸º LLM ä¼˜åŒ–ï¼‰

Usage:
    python3 context_fusion.py build <session_id> [--max-tokens 2000]
    python3 context_fusion.py add <session_id> <source_type> <content>
    python3 context_fusion.py prioritize <session_id>
    python3 context_fusion.py compress <text> [--max-lines 50]
"""

import argparse
import hashlib
import json
import os
import re
import sqlite3
import sys
import time
from contextlib import contextmanager
from compat_dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# æ•°æ®åº“è·¯å¾„
DEFAULT_DB_DIR = Path.home() / ".tmux-monitor" / "memory"
DEFAULT_DB_PATH = DEFAULT_DB_DIR / "monitor.db"
DB_PATH = Path(os.environ.get("AI_MONITOR_MEMORY_DB", str(DEFAULT_DB_PATH)))


class SourceType(Enum):
    """ä¿¡æ¯æ¥æºç±»å‹"""
    TERMINAL_OUTPUT = "terminal_output"
    FILE_CHANGE = "file_change"
    GIT_STATUS = "git_status"
    PROJECT_CONTEXT = "project_context"
    INTENT = "intent"
    GOAL = "goal"
    PROGRESS = "progress"
    ERROR = "error"
    DECISION_HISTORY = "decision_history"
    USER_INPUT = "user_input"


class Priority(Enum):
    """ä¿¡æ¯ä¼˜å…ˆçº§"""
    CRITICAL = 1    # é”™è¯¯ã€é˜»å¡
    HIGH = 2        # ç›®æ ‡ç›¸å…³ã€ç”¨æˆ·è¾“å…¥
    MEDIUM = 3      # è¿›åº¦ã€æ–‡ä»¶å˜æ›´
    LOW = 4         # æ™®é€šè¾“å‡ºã€å†å²
    BACKGROUND = 5  # é¡¹ç›®ç»“æ„ç­‰é™æ€ä¿¡æ¯


# ä¼˜å…ˆçº§é…ç½®
PRIORITY_CONFIG = {
    SourceType.ERROR: Priority.CRITICAL,
    SourceType.USER_INPUT: Priority.HIGH,
    SourceType.INTENT: Priority.HIGH,
    SourceType.GOAL: Priority.HIGH,
    SourceType.PROGRESS: Priority.MEDIUM,
    SourceType.FILE_CHANGE: Priority.MEDIUM,
    SourceType.TERMINAL_OUTPUT: Priority.MEDIUM,
    SourceType.GIT_STATUS: Priority.MEDIUM,
    SourceType.DECISION_HISTORY: Priority.LOW,
    SourceType.PROJECT_CONTEXT: Priority.BACKGROUND,
}

# å„æ¥æºçš„ Token é¢„ç®—æ¯”ä¾‹
TOKEN_BUDGET_RATIO = {
    Priority.CRITICAL: 0.30,    # 30% ç»™å…³é”®ä¿¡æ¯
    Priority.HIGH: 0.25,        # 25% ç»™é«˜ä¼˜å…ˆçº§
    Priority.MEDIUM: 0.25,      # 25% ç»™ä¸­ä¼˜å…ˆçº§
    Priority.LOW: 0.15,         # 15% ç»™ä½ä¼˜å…ˆçº§
    Priority.BACKGROUND: 0.05,  # 5% ç»™èƒŒæ™¯ä¿¡æ¯
}


@dataclass
class ContextItem:
    """ä¸Šä¸‹æ–‡é¡¹"""
    source_type: SourceType
    content: str
    priority: Priority = Priority.MEDIUM
    timestamp: int = 0
    metadata: Dict[str, Any] = field(default_factory=dict)
    relevance_score: float = 1.0  # ä¸å½“å‰ç›®æ ‡çš„ç›¸å…³åº¦

    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = int(time.time())
        if isinstance(self.source_type, str):
            self.source_type = SourceType(self.source_type)
        if isinstance(self.priority, int):
            self.priority = Priority(self.priority)
        elif isinstance(self.priority, str):
            self.priority = Priority[self.priority.upper()]

    def to_dict(self) -> Dict:
        return {
            "source_type": self.source_type.value,
            "content": self.content,
            "priority": self.priority.value,
            "timestamp": self.timestamp,
            "metadata": self.metadata,
            "relevance_score": self.relevance_score,
        }

    def content_hash(self) -> str:
        """è®¡ç®—å†…å®¹å“ˆå¸Œï¼ˆç”¨äºå»é‡ï¼‰"""
        return hashlib.md5(self.content.encode()).hexdigest()[:8]

    def estimate_tokens(self) -> int:
        """ä¼°ç®— token æ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰"""
        # è‹±æ–‡çº¦ 4 å­—ç¬¦/tokenï¼Œä¸­æ–‡çº¦ 1.5 å­—ç¬¦/token
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', self.content))
        other_chars = len(self.content) - chinese_chars
        return int(chinese_chars / 1.5 + other_chars / 4)


@dataclass
class FusedContext:
    """èåˆåçš„ä¸Šä¸‹æ–‡"""
    items: List[ContextItem] = field(default_factory=list)
    total_tokens: int = 0
    session_id: str = ""
    built_at: int = 0

    def to_formatted_string(self) -> str:
        """ç”Ÿæˆæ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
        sections = {}

        # æŒ‰æ¥æºç±»å‹åˆ†ç»„
        for item in self.items:
            source = item.source_type.value
            if source not in sections:
                sections[source] = []
            sections[source].append(item.content)

        # æ ¼å¼åŒ–è¾“å‡º
        parts = []

        # æŒ‰ä¼˜å…ˆçº§é¡ºåºè¾“å‡º
        source_order = [
            SourceType.ERROR,
            SourceType.INTENT,
            SourceType.GOAL,
            SourceType.PROGRESS,
            SourceType.USER_INPUT,
            SourceType.TERMINAL_OUTPUT,
            SourceType.FILE_CHANGE,
            SourceType.GIT_STATUS,
            SourceType.DECISION_HISTORY,
            SourceType.PROJECT_CONTEXT,
        ]

        for source_type in source_order:
            source = source_type.value
            if source in sections and sections[source]:
                section_header = self._get_section_header(source_type)
                content = "\n".join(sections[source])
                parts.append(f"{section_header}\n{content}")

        return "\n\n".join(parts)

    def _get_section_header(self, source_type: SourceType) -> str:
        """è·å–æ®µè½æ ‡é¢˜"""
        headers = {
            SourceType.ERROR: "ã€é”™è¯¯ä¿¡æ¯ã€‘",
            SourceType.INTENT: "ã€å½“å‰æ„å›¾ã€‘",
            SourceType.GOAL: "ã€ç›®æ ‡è¿›åº¦ã€‘",
            SourceType.PROGRESS: "ã€ä»»åŠ¡è¿›åº¦ã€‘",
            SourceType.USER_INPUT: "ã€ç”¨æˆ·è¾“å…¥ã€‘",
            SourceType.TERMINAL_OUTPUT: "ã€ç»ˆç«¯è¾“å‡ºã€‘",
            SourceType.FILE_CHANGE: "ã€æ–‡ä»¶å˜æ›´ã€‘",
            SourceType.GIT_STATUS: "ã€GitçŠ¶æ€ã€‘",
            SourceType.DECISION_HISTORY: "ã€å†å²å†³ç­–ã€‘",
            SourceType.PROJECT_CONTEXT: "ã€é¡¹ç›®ä¸Šä¸‹æ–‡ã€‘",
        }
        return headers.get(source_type, f"ã€{source_type.value}ã€‘")


class ContextFusion:
    """ä¸Šä¸‹æ–‡èåˆå™¨"""

    def __init__(self, db_path: Optional[Path] = None):
        self.db_path = db_path or DB_PATH
        self._ensure_db()

    @contextmanager
    def _get_conn(self):
        conn = sqlite3.connect(str(self.db_path))
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        finally:
            conn.close()

    def _ensure_db(self):
        """ç¡®ä¿æ•°æ®åº“å’Œè¡¨å­˜åœ¨"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        with self._get_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS context_items (
                    item_id TEXT PRIMARY KEY,
                    session_id TEXT NOT NULL,
                    source_type TEXT NOT NULL,
                    content TEXT NOT NULL,
                    content_hash TEXT,
                    priority INTEGER DEFAULT 3,
                    timestamp INTEGER,
                    metadata TEXT DEFAULT '{}',
                    relevance_score REAL DEFAULT 1.0
                )
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_context_session
                ON context_items(session_id, timestamp DESC)
            """)

    def add_item(self, session_id: str, source_type: SourceType, content: str,
                priority: Optional[Priority] = None, metadata: Dict = None) -> ContextItem:
        """æ·»åŠ ä¸Šä¸‹æ–‡é¡¹"""
        if not content or not content.strip():
            return None

        # ä½¿ç”¨é»˜è®¤ä¼˜å…ˆçº§
        if priority is None:
            priority = PRIORITY_CONFIG.get(source_type, Priority.MEDIUM)

        item = ContextItem(
            source_type=source_type,
            content=content.strip(),
            priority=priority,
            metadata=metadata or {},
        )

        # æ£€æŸ¥å»é‡
        if self._is_duplicate(session_id, item):
            return None

        # ä¿å­˜
        self._save_item(session_id, item)
        return item

    def _is_duplicate(self, session_id: str, item: ContextItem) -> bool:
        """æ£€æŸ¥æ˜¯å¦é‡å¤"""
        content_hash = item.content_hash()

        with self._get_conn() as conn:
            row = conn.execute("""
                SELECT 1 FROM context_items
                WHERE session_id = ? AND content_hash = ?
                AND timestamp > ?
                LIMIT 1
            """, (session_id, content_hash, int(time.time()) - 300)).fetchone()

            return row is not None

    def _save_item(self, session_id: str, item: ContextItem):
        """ä¿å­˜ä¸Šä¸‹æ–‡é¡¹"""
        import uuid
        item_id = str(uuid.uuid4())[:8]

        with self._get_conn() as conn:
            conn.execute("""
                INSERT INTO context_items
                (item_id, session_id, source_type, content, content_hash,
                 priority, timestamp, metadata, relevance_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                item_id,
                session_id,
                item.source_type.value,
                item.content,
                item.content_hash(),
                item.priority.value,
                item.timestamp,
                json.dumps(item.metadata, ensure_ascii=False),
                item.relevance_score,
            ))

    def build_context(self, session_id: str, max_tokens: int = 2000,
                     current_intent: str = "") -> FusedContext:
        """æ„å»ºèåˆä¸Šä¸‹æ–‡"""
        # è·å–æ‰€æœ‰ç›¸å…³é¡¹
        items = self._get_recent_items(session_id, limit=100)

        # è®¡ç®—ç›¸å…³åº¦
        if current_intent:
            items = self._calculate_relevance(items, current_intent)

        # æŒ‰ä¼˜å…ˆçº§å’Œç›¸å…³åº¦æ’åº
        items = self._prioritize(items)

        # å»é‡
        items = self._deduplicate(items)

        # æŒ‰ token é¢„ç®—åˆ†é…
        selected_items = self._allocate_budget(items, max_tokens)

        # å‹ç¼©è¿‡é•¿çš„å†…å®¹
        selected_items = self._compress_items(selected_items, max_tokens)

        # æ„å»ºç»“æœ
        fused = FusedContext(
            items=selected_items,
            total_tokens=sum(item.estimate_tokens() for item in selected_items),
            session_id=session_id,
            built_at=int(time.time()),
        )

        return fused

    def _get_recent_items(self, session_id: str, limit: int = 100) -> List[ContextItem]:
        """è·å–æœ€è¿‘çš„ä¸Šä¸‹æ–‡é¡¹"""
        with self._get_conn() as conn:
            rows = conn.execute("""
                SELECT * FROM context_items
                WHERE session_id = ?
                ORDER BY timestamp DESC
                LIMIT ?
            """, (session_id, limit)).fetchall()

            return [self._row_to_item(row) for row in rows]

    def _calculate_relevance(self, items: List[ContextItem], intent: str) -> List[ContextItem]:
        """è®¡ç®—ä¸å½“å‰æ„å›¾çš„ç›¸å…³åº¦"""
        intent_words = set(intent.lower().split())

        for item in items:
            content_words = set(item.content.lower().split())
            if intent_words and content_words:
                overlap = len(intent_words & content_words)
                item.relevance_score = min(1.0, 0.3 + (overlap / len(intent_words)) * 0.7)
            else:
                item.relevance_score = 0.5

        return items

    def _prioritize(self, items: List[ContextItem]) -> List[ContextItem]:
        """æŒ‰ä¼˜å…ˆçº§å’Œç›¸å…³åº¦æ’åº"""
        return sorted(items, key=lambda x: (
            x.priority.value,                    # ä¼˜å…ˆçº§ï¼ˆè¶Šå°è¶Šé«˜ï¼‰
            -x.relevance_score,                  # ç›¸å…³åº¦ï¼ˆè¶Šå¤§è¶Šé«˜ï¼‰
            -x.timestamp,                        # æ—¶é—´ï¼ˆè¶Šæ–°è¶Šé«˜ï¼‰
        ))

    def _deduplicate(self, items: List[ContextItem]) -> List[ContextItem]:
        """å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªå‡ºç°çš„ï¼‰"""
        seen_hashes = set()
        result = []

        for item in items:
            h = item.content_hash()
            if h not in seen_hashes:
                seen_hashes.add(h)
                result.append(item)

        return result

    def _allocate_budget(self, items: List[ContextItem], max_tokens: int) -> List[ContextItem]:
        """æŒ‰ä¼˜å…ˆçº§åˆ†é… token é¢„ç®—"""
        # è®¡ç®—æ¯ä¸ªä¼˜å…ˆçº§çš„é¢„ç®—
        budgets = {
            priority: int(max_tokens * ratio)
            for priority, ratio in TOKEN_BUDGET_RATIO.items()
        }

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„
        groups = {p: [] for p in Priority}
        for item in items:
            groups[item.priority].append(item)

        # åˆ†é…
        selected = []
        used_tokens = {p: 0 for p in Priority}

        for priority in Priority:
            budget = budgets[priority]
            for item in groups[priority]:
                tokens = item.estimate_tokens()
                if used_tokens[priority] + tokens <= budget:
                    selected.append(item)
                    used_tokens[priority] += tokens
                elif tokens < budget * 0.5:
                    # å¦‚æœé¡¹ç›®è¾ƒå°ï¼Œå°è¯•æŒ¤è¿›å»
                    selected.append(item)
                    used_tokens[priority] += tokens

        return selected

    def _compress_items(self, items: List[ContextItem], max_tokens: int) -> List[ContextItem]:
        """å‹ç¼©è¿‡é•¿çš„å†…å®¹"""
        total_tokens = sum(item.estimate_tokens() for item in items)

        if total_tokens <= max_tokens:
            return items

        # éœ€è¦å‹ç¼©
        ratio = max_tokens / total_tokens

        for item in items:
            if item.priority.value >= Priority.MEDIUM.value:
                # ä½ä¼˜å…ˆçº§çš„å†…å®¹è¿›è¡Œå‹ç¼©
                item.content = self._compress_content(item.content, ratio)

        return items

    def _compress_content(self, content: str, ratio: float) -> str:
        """å‹ç¼©å†…å®¹"""
        lines = content.split('\n')
        target_lines = max(3, int(len(lines) * ratio))

        if len(lines) <= target_lines:
            return content

        # ä¿ç•™å¼€å¤´å’Œç»“å°¾
        keep_start = target_lines // 2
        keep_end = target_lines - keep_start - 1

        result = lines[:keep_start]
        result.append(f"... ({len(lines) - target_lines} è¡Œå·²çœç•¥) ...")
        result.extend(lines[-keep_end:] if keep_end > 0 else [])

        return '\n'.join(result)

    def get_summary(self, session_id: str, max_tokens: int = 500) -> str:
        """è·å–ä¸Šä¸‹æ–‡æ‘˜è¦ï¼ˆç”¨äº LLMï¼‰"""
        fused = self.build_context(session_id, max_tokens)
        return fused.to_formatted_string()

    def clear_old_items(self, session_id: str, max_age_seconds: int = 3600):
        """æ¸…ç†æ—§çš„ä¸Šä¸‹æ–‡é¡¹"""
        cutoff = int(time.time()) - max_age_seconds

        with self._get_conn() as conn:
            conn.execute("""
                DELETE FROM context_items
                WHERE session_id = ? AND timestamp < ?
            """, (session_id, cutoff))

    def _row_to_item(self, row) -> ContextItem:
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º ContextItem"""
        return ContextItem(
            source_type=SourceType(row['source_type']),
            content=row['content'],
            priority=Priority(row['priority']),
            timestamp=row['timestamp'],
            metadata=json.loads(row['metadata'] or '{}'),
            relevance_score=row['relevance_score'] or 1.0,
        )


class ContextBuilder:
    """ä¸Šä¸‹æ–‡æ„å»ºå™¨ - ä¾¿æ·æ¥å£"""

    def __init__(self, session_id: str, fusion: Optional[ContextFusion] = None):
        self.session_id = session_id
        self.fusion = fusion or ContextFusion()

    def add_terminal_output(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ ç»ˆç«¯è¾“å‡º"""
        self.fusion.add_item(self.session_id, SourceType.TERMINAL_OUTPUT, content)
        return self

    def add_error(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ é”™è¯¯ä¿¡æ¯"""
        self.fusion.add_item(self.session_id, SourceType.ERROR, content)
        return self

    def add_intent(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ æ„å›¾ä¿¡æ¯"""
        self.fusion.add_item(self.session_id, SourceType.INTENT, content)
        return self

    def add_goal(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ ç›®æ ‡ä¿¡æ¯"""
        self.fusion.add_item(self.session_id, SourceType.GOAL, content)
        return self

    def add_progress(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ è¿›åº¦ä¿¡æ¯"""
        self.fusion.add_item(self.session_id, SourceType.PROGRESS, content)
        return self

    def add_file_change(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ æ–‡ä»¶å˜æ›´ä¿¡æ¯"""
        self.fusion.add_item(self.session_id, SourceType.FILE_CHANGE, content)
        return self

    def add_git_status(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ  Git çŠ¶æ€"""
        self.fusion.add_item(self.session_id, SourceType.GIT_STATUS, content)
        return self

    def add_decision_history(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ å†å²å†³ç­–"""
        self.fusion.add_item(self.session_id, SourceType.DECISION_HISTORY, content)
        return self

    def add_project_context(self, content: str) -> 'ContextBuilder':
        """æ·»åŠ é¡¹ç›®ä¸Šä¸‹æ–‡"""
        self.fusion.add_item(self.session_id, SourceType.PROJECT_CONTEXT, content)
        return self

    def build(self, max_tokens: int = 2000, current_intent: str = "") -> str:
        """æ„å»ºæœ€ç»ˆä¸Šä¸‹æ–‡"""
        fused = self.fusion.build_context(self.session_id, max_tokens, current_intent)
        return fused.to_formatted_string()


# ==================== CLI å…¥å£ ====================

def main(argv=None):
    parser = argparse.ArgumentParser(
        description='Claude Monitor Context Fusion',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # build
    p_build = subparsers.add_parser('build', help='Build fused context')
    p_build.add_argument('session_id', help='Session ID')
    p_build.add_argument('--max-tokens', '-t', type=int, default=2000,
                        help='Maximum tokens')
    p_build.add_argument('--intent', '-i', default='', help='Current intent for relevance')
    p_build.add_argument('--json', action='store_true', help='Output as JSON')

    # add
    p_add = subparsers.add_parser('add', help='Add context item')
    p_add.add_argument('session_id', help='Session ID')
    p_add.add_argument('source_type', choices=[s.value for s in SourceType],
                      help='Source type')
    p_add.add_argument('content', nargs='?', help='Content (or read from stdin)')

    # prioritize
    p_prioritize = subparsers.add_parser('prioritize', help='Show prioritized items')
    p_prioritize.add_argument('session_id', help='Session ID')
    p_prioritize.add_argument('--limit', '-l', type=int, default=20)

    # compress
    p_compress = subparsers.add_parser('compress', help='Compress text')
    p_compress.add_argument('text', nargs='?', help='Text to compress (or read from stdin)')
    p_compress.add_argument('--max-lines', '-l', type=int, default=50)

    # clear
    p_clear = subparsers.add_parser('clear', help='Clear old items')
    p_clear.add_argument('session_id', help='Session ID')
    p_clear.add_argument('--max-age', '-a', type=int, default=3600,
                        help='Max age in seconds')

    args = parser.parse_args(argv)
    fusion = ContextFusion()

    try:
        if args.command == 'build':
            fused = fusion.build_context(args.session_id, args.max_tokens, args.intent)
            if args.json:
                output = {
                    "session_id": fused.session_id,
                    "total_tokens": fused.total_tokens,
                    "item_count": len(fused.items),
                    "built_at": fused.built_at,
                    "formatted": fused.to_formatted_string(),
                }
                print(json.dumps(output, indent=2, ensure_ascii=False))
            else:
                print(fused.to_formatted_string())

        elif args.command == 'add':
            content = args.content
            if not content:
                content = sys.stdin.read()

            source_type = SourceType(args.source_type)
            item = fusion.add_item(args.session_id, source_type, content)

            if item:
                print(f"Added {source_type.value} item (priority: {item.priority.value})")
            else:
                print("Item was duplicate or empty, not added")

        elif args.command == 'prioritize':
            items = fusion._get_recent_items(args.session_id, args.limit)
            items = fusion._prioritize(items)

            for item in items[:args.limit]:
                priority_icons = {1: "ğŸ”´", 2: "ğŸŸ ", 3: "ğŸŸ¡", 4: "ğŸŸ¢", 5: "âšª"}
                icon = priority_icons.get(item.priority.value, "?")
                preview = item.content[:60].replace('\n', ' ')
                print(f"{icon} [{item.source_type.value}] {preview}...")

        elif args.command == 'compress':
            text = args.text
            if not text:
                text = sys.stdin.read()

            lines = text.split('\n')
            if len(lines) > args.max_lines:
                keep = args.max_lines // 2
                result = lines[:keep]
                result.append(f"... ({len(lines) - args.max_lines} è¡Œå·²çœç•¥) ...")
                result.extend(lines[-(args.max_lines - keep - 1):])
                print('\n'.join(result))
            else:
                print(text)

        elif args.command == 'clear':
            fusion.clear_old_items(args.session_id, args.max_age)
            print(f"Cleared items older than {args.max_age} seconds")

        else:
            parser.print_help()
            return 1

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
