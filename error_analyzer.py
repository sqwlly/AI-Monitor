#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Claude Monitor Error Analyzer
é”™è¯¯è¯­ä¹‰åˆ†æå™¨ - ç†è§£é”™è¯¯çš„æœ¬è´¨å’Œæ ¹å› 

åŠŸèƒ½ï¼š
1. é”™è¯¯åˆ†ç±»ï¼ˆè¯­æ³•/è¿è¡Œæ—¶/ä¾èµ–/é…ç½®/ç½‘ç»œ/é€»è¾‘ï¼‰
2. æ ¹å› æ¨æ–­ï¼ˆå †æ ˆè§£æã€ä¸Šä¸‹æ–‡å…³è”ï¼‰
3. ä¿®å¤å»ºè®®ç”Ÿæˆ
4. å†å²ç›¸ä¼¼é”™è¯¯åŒ¹é…

Usage:
    python3 error_analyzer.py analyze <session_id> <text>
    python3 error_analyzer.py history <session_id>
    python3 error_analyzer.py suggest <error_id>
    python3 error_analyzer.py resolve <error_id> <fix_result>
"""

import argparse
import hashlib
import json
import os
import re
import sqlite3
import sys
import time
import uuid
from contextlib import contextmanager
from pathlib import Path

# æ•°æ®åº“è·¯å¾„
DEFAULT_DB_DIR = Path.home() / ".tmux-monitor" / "memory"
DEFAULT_DB_PATH = DEFAULT_DB_DIR / "monitor.db"
DB_PATH = Path(os.environ.get("AI_MONITOR_MEMORY_DB", str(DEFAULT_DB_PATH)))

# é”™è¯¯ç±»å‹å®šä¹‰
ERROR_TYPES = {
    "syntax": {
        "name": "è¯­æ³•é”™è¯¯",
        "patterns": [
            r"SyntaxError",
            r"ParseError",
            r"IndentationError",
            r"unexpected token",
            r"invalid syntax",
            r"parsing error",
        ],
        "suggestions": [
            "æ£€æŸ¥è¯­æ³•æ ¼å¼",
            "æ£€æŸ¥æ‹¬å·/å¼•å·æ˜¯å¦åŒ¹é…",
            "æ£€æŸ¥ç¼©è¿›æ˜¯å¦æ­£ç¡®",
        ],
    },
    "runtime": {
        "name": "è¿è¡Œæ—¶é”™è¯¯",
        "patterns": [
            r"RuntimeError",
            r"TypeError",
            r"ValueError",
            r"AttributeError",
            r"KeyError",
            r"IndexError",
            r"ZeroDivisionError",
            r"NullPointerException",
            r"undefined is not",
            r"Cannot read property",
        ],
        "suggestions": [
            "æ£€æŸ¥å˜é‡ç±»å‹æ˜¯å¦æ­£ç¡®",
            "æ£€æŸ¥ç©ºå€¼å¤„ç†",
            "æ·»åŠ è¾¹ç•Œæ¡ä»¶æ£€æŸ¥",
        ],
    },
    "dependency": {
        "name": "ä¾èµ–é”™è¯¯",
        "patterns": [
            r"ModuleNotFoundError",
            r"ImportError",
            r"No module named",
            r"Cannot find module",
            r"Package .+ not found",
            r"require\(\) of ES Module",
            r"Module not found",
        ],
        "suggestions": [
            "è¿è¡Œ pip install / npm install",
            "æ£€æŸ¥ requirements.txt / package.json",
            "æ£€æŸ¥æ¨¡å—è·¯å¾„æ˜¯å¦æ­£ç¡®",
        ],
    },
    "config": {
        "name": "é…ç½®é”™è¯¯",
        "patterns": [
            r"FileNotFoundError",
            r"ENOENT",
            r"PermissionError",
            r"EACCES",
            r"ConfigurationError",
            r"Environment variable .+ not set",
            r"Missing required",
            r"Invalid configuration",
        ],
        "suggestions": [
            "æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®",
            "æ£€æŸ¥æ–‡ä»¶æƒé™",
            "æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®",
            "æ£€æŸ¥ .env æ–‡ä»¶",
        ],
    },
    "network": {
        "name": "ç½‘ç»œé”™è¯¯",
        "patterns": [
            r"ConnectionError",
            r"TimeoutError",
            r"ETIMEDOUT",
            r"ECONNREFUSED",
            r"Connection refused",
            r"Network is unreachable",
            r"getaddrinfo",
            r"socket hang up",
            r"CORS",
        ],
        "suggestions": [
            "æ£€æŸ¥ç½‘ç»œè¿æ¥",
            "æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯åŠ¨",
            "æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨",
            "æ£€æŸ¥é˜²ç«å¢™è®¾ç½®",
        ],
    },
    "database": {
        "name": "æ•°æ®åº“é”™è¯¯",
        "patterns": [
            r"OperationalError",
            r"IntegrityError",
            r"DatabaseError",
            r"Connection to .+ failed",
            r"duplicate key",
            r"foreign key constraint",
            r"table .+ doesn't exist",
        ],
        "suggestions": [
            "æ£€æŸ¥æ•°æ®åº“è¿æ¥é…ç½®",
            "æ£€æŸ¥è¡¨ç»“æ„æ˜¯å¦æ­£ç¡®",
            "æ£€æŸ¥æ•°æ®çº¦æŸ",
            "è¿è¡Œæ•°æ®åº“è¿ç§»",
        ],
    },
    "assertion": {
        "name": "æ–­è¨€/æµ‹è¯•é”™è¯¯",
        "patterns": [
            r"AssertionError",
            r"FAILED",
            r"Expected .+ but got",
            r"does not match",
            r"should be",
            r"to equal",
            r"toBe",
            r"assert",
        ],
        "suggestions": [
            "æ£€æŸ¥é¢„æœŸå€¼ä¸å®é™…å€¼",
            "æ£€æŸ¥æµ‹è¯•æ•°æ®",
            "æ£€æŸ¥ä¸šåŠ¡é€»è¾‘å®ç°",
        ],
    },
    "memory": {
        "name": "å†…å­˜é”™è¯¯",
        "patterns": [
            r"MemoryError",
            r"OutOfMemoryError",
            r"heap out of memory",
            r"JavaScript heap",
            r"allocation failed",
        ],
        "suggestions": [
            "å‡å°‘æ•°æ®å¤„ç†é‡",
            "å¢åŠ å†…å­˜é™åˆ¶",
            "ä¼˜åŒ–å†…å­˜ä½¿ç”¨",
            "ä½¿ç”¨æµå¼å¤„ç†",
        ],
    },
    "auth": {
        "name": "è®¤è¯/æˆæƒé”™è¯¯",
        "patterns": [
            r"401",
            r"403",
            r"Unauthorized",
            r"Forbidden",
            r"Invalid token",
            r"Authentication failed",
            r"Permission denied",
        ],
        "suggestions": [
            "æ£€æŸ¥è®¤è¯å‡­æ®",
            "æ£€æŸ¥ token æ˜¯å¦è¿‡æœŸ",
            "æ£€æŸ¥æƒé™é…ç½®",
        ],
    },
}

# ä¸¥é‡ç¨‹åº¦åˆ¤æ–­
SEVERITY_PATTERNS = {
    "critical": [
        r"FATAL",
        r"CRITICAL",
        r"panic",
        r"segmentation fault",
        r"core dumped",
        r"system error",
    ],
    "high": [
        r"ERROR",
        r"Exception",
        r"FAILED",
        r"crash",
    ],
    "medium": [
        r"WARNING",
        r"WARN",
        r"deprecated",
    ],
    "low": [
        r"INFO",
        r"NOTE",
        r"hint",
    ],
}


class ErrorAnalysis:
    """é”™è¯¯åˆ†æç»“æœ"""

    def __init__(self, error_id=None, session_id=None, raw_error="",
                 error_type="unknown", error_signature="", severity="medium",
                 root_cause="", related_files=None, suggested_fixes=None,
                 applied_fix=None, fix_result=None, created_at=None,
                 resolved_at=None, **kwargs):
        self.error_id = error_id or str(uuid.uuid4())[:8]
        self.session_id = session_id
        self.raw_error = raw_error
        self.error_type = error_type
        self.error_signature = error_signature
        self.severity = severity
        self.root_cause = root_cause
        self.related_files = related_files or []
        self.suggested_fixes = suggested_fixes or []
        self.applied_fix = applied_fix
        self.fix_result = fix_result
        self.created_at = created_at or int(time.time())
        self.resolved_at = resolved_at

    def to_dict(self):
        return {
            "error_id": self.error_id,
            "session_id": self.session_id,
            "raw_error": self.raw_error[:500],
            "error_type": self.error_type,
            "error_signature": self.error_signature,
            "severity": self.severity,
            "root_cause": self.root_cause,
            "related_files": self.related_files,
            "suggested_fixes": self.suggested_fixes,
            "applied_fix": self.applied_fix,
            "fix_result": self.fix_result,
            "created_at": self.created_at,
            "resolved_at": self.resolved_at,
        }

    def to_context_string(self):
        """ç”Ÿæˆç”¨äº LLM ä¸Šä¸‹æ–‡çš„å­—ç¬¦ä¸²"""
        type_name = ERROR_TYPES.get(self.error_type, {}).get("name", self.error_type)
        severity_icon = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(self.severity, "âšª")

        result = f"[error] {severity_icon} {type_name}: {self.root_cause[:100]}"

        if self.related_files:
            result += f" | ç›¸å…³æ–‡ä»¶: {', '.join(self.related_files[:3])}"

        if self.suggested_fixes:
            result += f" | å»ºè®®: {self.suggested_fixes[0]}"

        return result


class ErrorAnalyzer:
    """é”™è¯¯è¯­ä¹‰åˆ†æå™¨"""

    def __init__(self, db_path=None):
        self.db_path = db_path or DB_PATH
        self._ensure_db()

    @contextmanager
    def _get_conn(self):
        conn = sqlite3.connect(str(self.db_path))
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        finally:
            conn.close()

    def _ensure_db(self):
        """ç¡®ä¿æ•°æ®åº“å’Œè¡¨å­˜åœ¨"""
        self.db_path.parent.mkdir(parents=True, exist_ok=True)

        with self._get_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS error_analysis (
                    error_id TEXT PRIMARY KEY,
                    session_id TEXT,
                    raw_error TEXT,
                    error_type TEXT,
                    error_signature TEXT,
                    severity TEXT,
                    root_cause TEXT,
                    related_files TEXT,
                    suggested_fixes TEXT,
                    applied_fix TEXT,
                    fix_result TEXT,
                    created_at INTEGER,
                    resolved_at INTEGER
                )
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_error_session
                ON error_analysis(session_id)
            """)
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_error_signature
                ON error_analysis(error_signature)
            """)

    def analyze(self, session_id, text):
        """åˆ†ææ–‡æœ¬ä¸­çš„é”™è¯¯"""
        if not text or not text.strip():
            return None

        # æ£€æµ‹æ˜¯å¦åŒ…å«é”™è¯¯
        if not self._contains_error(text):
            return None

        # æå–é”™è¯¯ä¿¡æ¯
        error_text = self._extract_error_text(text)

        # åˆ†ç±»é”™è¯¯
        error_type = self._classify_error(error_text)

        # åˆ¤æ–­ä¸¥é‡ç¨‹åº¦
        severity = self._assess_severity(error_text)

        # ç”Ÿæˆé”™è¯¯ç­¾åï¼ˆç”¨äºåŒ¹é…ç›¸ä¼¼é”™è¯¯ï¼‰
        signature = self._generate_signature(error_text, error_type)

        # æå–ç›¸å…³æ–‡ä»¶
        related_files = self._extract_related_files(text)

        # æ¨æ–­æ ¹å› 
        root_cause = self._infer_root_cause(error_text, error_type, related_files)

        # ç”Ÿæˆä¿®å¤å»ºè®®
        suggestions = self._generate_suggestions(error_type, error_text, root_cause)

        # æŸ¥æ‰¾å†å²ç›¸ä¼¼é”™è¯¯
        similar_errors = self._find_similar_errors(signature)
        if similar_errors:
            # ä»å†å²ä¸­æå–æˆåŠŸçš„ä¿®å¤æ–¹æ¡ˆ
            for err in similar_errors:
                if err.fix_result == "success" and err.applied_fix:
                    suggestions.insert(0, f"[å†å²æˆåŠŸæ–¹æ¡ˆ] {err.applied_fix}")
                    break

        analysis = ErrorAnalysis(
            session_id=session_id,
            raw_error=error_text,
            error_type=error_type,
            error_signature=signature,
            severity=severity,
            root_cause=root_cause,
            related_files=related_files,
            suggested_fixes=suggestions[:5],  # æœ€å¤š5æ¡å»ºè®®
        )

        # ä¿å­˜åˆ†æç»“æœ
        self._save_analysis(analysis)

        return analysis

    def _contains_error(self, text):
        """æ£€æµ‹æ–‡æœ¬æ˜¯å¦åŒ…å«é”™è¯¯"""
        error_indicators = [
            r'\bError\b', r'\bException\b', r'\bFAILED\b', r'\bFailed\b',
            r'\bTraceback\b', r'\bpanic\b', r'\bfatal\b', r'\bcrash\b',
            r'é”™è¯¯', r'å¤±è´¥', r'å¼‚å¸¸',
        ]
        text_lower = text.lower()
        for pattern in error_indicators:
            if re.search(pattern, text, re.IGNORECASE):
                return True
        return False

    def _extract_error_text(self, text):
        """æå–æ ¸å¿ƒé”™è¯¯ä¿¡æ¯"""
        lines = text.strip().split('\n')

        # æŸ¥æ‰¾ Traceback
        traceback_start = -1
        for i, line in enumerate(lines):
            if 'Traceback' in line or 'Error:' in line or 'Exception:' in line:
                traceback_start = i
                break

        if traceback_start >= 0:
            # æå– traceback åŠå…¶åçš„å†…å®¹
            error_lines = lines[traceback_start:]
            return '\n'.join(error_lines[:30])  # æœ€å¤š30è¡Œ

        # æŸ¥æ‰¾åŒ…å« error/exception çš„è¡ŒåŠå…¶ä¸Šä¸‹æ–‡
        for i, line in enumerate(lines):
            if re.search(r'(error|exception|failed)', line, re.IGNORECASE):
                start = max(0, i - 3)
                end = min(len(lines), i + 5)
                return '\n'.join(lines[start:end])

        # è¿”å›æœ€å20è¡Œ
        return '\n'.join(lines[-20:])

    def _classify_error(self, error_text):
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        for error_type, config in ERROR_TYPES.items():
            for pattern in config["patterns"]:
                if re.search(pattern, error_text, re.IGNORECASE):
                    return error_type
        return "unknown"

    def _assess_severity(self, error_text):
        """è¯„ä¼°é”™è¯¯ä¸¥é‡ç¨‹åº¦"""
        for severity, patterns in SEVERITY_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, error_text, re.IGNORECASE):
                    return severity
        return "medium"

    def _generate_signature(self, error_text, error_type):
        """ç”Ÿæˆé”™è¯¯ç­¾å"""
        # æå–å…³é”®é”™è¯¯ä¿¡æ¯
        key_parts = []

        # é”™è¯¯ç±»å‹
        key_parts.append(error_type)

        # æå–é”™è¯¯ç±»åï¼ˆå¦‚ TypeError, ValueErrorï¼‰
        error_class_match = re.search(r'\b(\w+Error|\w+Exception)\b', error_text)
        if error_class_match:
            key_parts.append(error_class_match.group(1))

        # æå–é”™è¯¯æ¶ˆæ¯çš„å…³é”®è¯
        error_msg_match = re.search(r'(?:Error|Exception)[:\s]+(.+?)(?:\n|$)', error_text)
        if error_msg_match:
            msg = error_msg_match.group(1)
            # ç§»é™¤å˜é‡å€¼ï¼Œä¿ç•™ç»“æ„
            msg = re.sub(r'["\'][^"\']+["\']', '""', msg)
            msg = re.sub(r'\d+', 'N', msg)
            key_parts.append(msg[:100])

        signature_str = '|'.join(key_parts)
        return hashlib.sha256(signature_str.encode()).hexdigest()[:16]

    def _extract_related_files(self, text):
        """æå–ç›¸å…³æ–‡ä»¶"""
        files = set()

        # åŒ¹é…æ–‡ä»¶è·¯å¾„
        file_patterns = [
            r'File ["\']([^"\']+)["\']',
            r'at ([^\s:]+):(\d+)',
            r'in ([^\s:]+):(\d+)',
            r'([/\\][\w/\\.-]+\.(py|js|ts|go|rs|java|rb|php|c|cpp|h))',
        ]

        for pattern in file_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if isinstance(match, tuple):
                    file_path = match[0]
                else:
                    file_path = match
                # æ¸…ç†è·¯å¾„
                file_path = file_path.strip()
                if file_path and len(file_path) < 200:
                    # åªä¿ç•™æ–‡ä»¶åå’Œæœ€è¿‘çš„ç›®å½•
                    parts = file_path.replace('\\', '/').split('/')
                    if len(parts) > 2:
                        file_path = '/'.join(parts[-2:])
                    files.add(file_path)

        return list(files)[:5]  # æœ€å¤š5ä¸ªæ–‡ä»¶

    def _infer_root_cause(self, error_text, error_type, related_files):
        """æ¨æ–­æ ¹å› """
        # æå–é”™è¯¯æ¶ˆæ¯
        error_msg = ""
        msg_match = re.search(r'(?:Error|Exception)[:\s]+(.+?)(?:\n|$)', error_text, re.IGNORECASE)
        if msg_match:
            error_msg = msg_match.group(1).strip()

        # æ ¹æ®é”™è¯¯ç±»å‹å’Œæ¶ˆæ¯æ¨æ–­æ ¹å› 
        if error_type == "dependency":
            module_match = re.search(r"No module named ['\"]?(\w+)", error_text)
            if module_match:
                return f"ç¼ºå°‘æ¨¡å— {module_match.group(1)}ï¼Œéœ€è¦å®‰è£…"

        elif error_type == "config":
            file_match = re.search(r"(?:No such file|FileNotFoundError)[:\s]*['\"]?([^'\"]+)", error_text)
            if file_match:
                return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_match.group(1)}"

        elif error_type == "syntax":
            line_match = re.search(r"line (\d+)", error_text)
            if line_match and related_files:
                return f"{related_files[0]} ç¬¬ {line_match.group(1)} è¡Œè¯­æ³•é”™è¯¯"

        elif error_type == "assertion":
            expected_match = re.search(r"[Ee]xpected[:\s]+(.+?)\s+(?:but got|to equal|received)[:\s]+(.+?)(?:\n|$)", error_text)
            if expected_match:
                return f"é¢„æœŸ {expected_match.group(1).strip()[:30]}ï¼Œå®é™… {expected_match.group(2).strip()[:30]}"

        elif error_type == "runtime":
            if "NoneType" in error_text or "undefined" in error_text or "null" in error_text:
                return "ç©ºå€¼/æœªå®šä¹‰å˜é‡è®¿é—®"
            if "KeyError" in error_text or "key" in error_msg.lower():
                key_match = re.search(r"KeyError[:\s]*['\"]?(\w+)", error_text)
                if key_match:
                    return f"å­—å…¸ç¼ºå°‘é”®: {key_match.group(1)}"

        # é»˜è®¤è¿”å›é”™è¯¯æ¶ˆæ¯çš„ç®€åŒ–ç‰ˆ
        if error_msg:
            return error_msg[:100]

        return "æœªèƒ½ç¡®å®šå…·ä½“åŸå› "

    def _generate_suggestions(self, error_type, error_text, root_cause):
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions = []

        # è·å–é”™è¯¯ç±»å‹çš„é€šç”¨å»ºè®®
        if error_type in ERROR_TYPES:
            suggestions.extend(ERROR_TYPES[error_type]["suggestions"])

        # æ ¹æ®å…·ä½“æƒ…å†µæ·»åŠ é’ˆå¯¹æ€§å»ºè®®
        if error_type == "dependency":
            module_match = re.search(r"No module named ['\"]?(\w+)", error_text)
            if module_match:
                module = module_match.group(1)
                suggestions.insert(0, f"è¿è¡Œ: pip install {module}")

        elif error_type == "config":
            if ".env" in error_text or "environment" in error_text.lower():
                suggestions.insert(0, "æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”é…ç½®æ­£ç¡®")

        elif error_type == "database":
            if "migration" in error_text.lower() or "migrate" in error_text.lower():
                suggestions.insert(0, "è¿è¡Œæ•°æ®åº“è¿ç§»å‘½ä»¤")

        elif error_type == "network":
            if "ECONNREFUSED" in error_text:
                suggestions.insert(0, "æ£€æŸ¥ç›®æ ‡æœåŠ¡æ˜¯å¦å·²å¯åŠ¨")

        return suggestions

    def _find_similar_errors(self, signature):
        """æŸ¥æ‰¾ç›¸ä¼¼é”™è¯¯"""
        with self._get_conn() as conn:
            rows = conn.execute("""
                SELECT * FROM error_analysis
                WHERE error_signature = ? AND fix_result IS NOT NULL
                ORDER BY created_at DESC
                LIMIT 5
            """, (signature,)).fetchall()

            return [self._row_to_analysis(row) for row in rows]

    def _save_analysis(self, analysis):
        """ä¿å­˜åˆ†æç»“æœ"""
        with self._get_conn() as conn:
            conn.execute("""
                INSERT OR REPLACE INTO error_analysis
                (error_id, session_id, raw_error, error_type, error_signature,
                 severity, root_cause, related_files, suggested_fixes,
                 applied_fix, fix_result, created_at, resolved_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                analysis.error_id,
                analysis.session_id,
                analysis.raw_error,
                analysis.error_type,
                analysis.error_signature,
                analysis.severity,
                analysis.root_cause,
                json.dumps(analysis.related_files, ensure_ascii=False),
                json.dumps(analysis.suggested_fixes, ensure_ascii=False),
                analysis.applied_fix,
                analysis.fix_result,
                analysis.created_at,
                analysis.resolved_at,
            ))

    def get_recent_errors(self, session_id, limit=5):
        """è·å–æœ€è¿‘çš„é”™è¯¯"""
        with self._get_conn() as conn:
            rows = conn.execute("""
                SELECT * FROM error_analysis
                WHERE session_id = ?
                ORDER BY created_at DESC
                LIMIT ?
            """, (session_id, limit)).fetchall()

            return [self._row_to_analysis(row) for row in rows]

    def get_unresolved_errors(self, session_id):
        """è·å–æœªè§£å†³çš„é”™è¯¯"""
        with self._get_conn() as conn:
            rows = conn.execute("""
                SELECT * FROM error_analysis
                WHERE session_id = ? AND resolved_at IS NULL
                ORDER BY created_at DESC
            """, (session_id,)).fetchall()

            return [self._row_to_analysis(row) for row in rows]

    def resolve_error(self, error_id, applied_fix, fix_result):
        """æ ‡è®°é”™è¯¯å·²è§£å†³"""
        with self._get_conn() as conn:
            conn.execute("""
                UPDATE error_analysis
                SET applied_fix = ?, fix_result = ?, resolved_at = ?
                WHERE error_id = ?
            """, (applied_fix, fix_result, int(time.time()), error_id))

    def get_error_summary(self, session_id):
        """è·å–é”™è¯¯æ‘˜è¦ï¼ˆç”¨äº LLM ä¸Šä¸‹æ–‡ï¼‰"""
        errors = self.get_unresolved_errors(session_id)
        if not errors:
            return ""

        # åªè¿”å›æœ€æ–°çš„æœªè§£å†³é”™è¯¯
        latest = errors[0]
        return latest.to_context_string()

    def _row_to_analysis(self, row):
        """å°†æ•°æ®åº“è¡Œè½¬æ¢ä¸º ErrorAnalysis å¯¹è±¡"""
        return ErrorAnalysis(
            error_id=row['error_id'],
            session_id=row['session_id'],
            raw_error=row['raw_error'],
            error_type=row['error_type'],
            error_signature=row['error_signature'],
            severity=row['severity'],
            root_cause=row['root_cause'],
            related_files=json.loads(row['related_files'] or '[]'),
            suggested_fixes=json.loads(row['suggested_fixes'] or '[]'),
            applied_fix=row['applied_fix'],
            fix_result=row['fix_result'],
            created_at=row['created_at'],
            resolved_at=row['resolved_at'],
        )


# ==================== CLI å…¥å£ ====================

def main(argv=None):
    parser = argparse.ArgumentParser(
        description='Claude Monitor Error Analyzer',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # analyze
    p_analyze = subparsers.add_parser('analyze', help='Analyze error from text')
    p_analyze.add_argument('session_id', help='Session ID')
    p_analyze.add_argument('text', nargs='?', help='Text to analyze (or read from stdin)')

    # history
    p_history = subparsers.add_parser('history', help='Get error history')
    p_history.add_argument('session_id', help='Session ID')
    p_history.add_argument('--limit', type=int, default=10)

    # suggest
    p_suggest = subparsers.add_parser('suggest', help='Get suggestions for an error')
    p_suggest.add_argument('error_id', help='Error ID')

    # resolve
    p_resolve = subparsers.add_parser('resolve', help='Mark error as resolved')
    p_resolve.add_argument('error_id', help='Error ID')
    p_resolve.add_argument('fix_result', choices=['success', 'failed', 'partial'])
    p_resolve.add_argument('--fix', help='Applied fix description')

    # summary
    p_summary = subparsers.add_parser('summary', help='Get error summary for LLM context')
    p_summary.add_argument('session_id', help='Session ID')

    args = parser.parse_args(argv)
    ea = ErrorAnalyzer()

    try:
        if args.command == 'analyze':
            text = args.text
            if not text:
                text = sys.stdin.read()

            analysis = ea.analyze(args.session_id, text)
            if analysis:
                print(json.dumps(analysis.to_dict(), indent=2, ensure_ascii=False))
            else:
                print("{}")

        elif args.command == 'history':
            errors = ea.get_recent_errors(args.session_id, args.limit)
            for err in errors:
                status = "âœ…" if err.resolved_at else "âŒ"
                severity_icon = {"critical": "ğŸ”´", "high": "ğŸŸ ", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(err.severity, "âšª")
                type_name = ERROR_TYPES.get(err.error_type, {}).get("name", err.error_type)
                print(f"{status} {severity_icon} [{type_name}] {err.root_cause[:60]}")

        elif args.command == 'suggest':
            with ea._get_conn() as conn:
                row = conn.execute("SELECT * FROM error_analysis WHERE error_id = ?", (args.error_id,)).fetchone()
                if row:
                    analysis = ea._row_to_analysis(row)
                    print("ä¿®å¤å»ºè®®:")
                    for i, sug in enumerate(analysis.suggested_fixes, 1):
                        print(f"  {i}. {sug}")
                else:
                    print("Error not found")

        elif args.command == 'resolve':
            ea.resolve_error(args.error_id, args.fix or "", args.fix_result)
            print(f"Error {args.error_id} marked as {args.fix_result}")

        elif args.command == 'summary':
            summary = ea.get_error_summary(args.session_id)
            if summary:
                print(summary)

        else:
            parser.print_help()
            return 1

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        return 1

    return 0


if __name__ == '__main__':
    sys.exit(main())
